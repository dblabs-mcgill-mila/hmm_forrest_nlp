# hmm_forrest_nlp

## 1. Create the enviroment based on requirements.txt.

```
pip install -r requirements.txt
```

## 2. Download the intermediate data used for data analysis in the google drive: 
https://drive.google.com/drive/folders/1Fq0XzNU0qN6bIFVhH3pBwXqPKOWznx6t?usp=sharing

Unzip the tmp_data_open.zip, and use its path to replace the **tmp_dir** variable in the scripts.
Unzip the hmmlearn.zip, and use its path to **path_to_raw_hmm_models** in the scripts.


## 3. The original data preprocessing scripts are in the preprocesssing folder, the approval and download of studyforrest data is needed to run the script.
## 4. The training scripts of HMM models are in the training folder. We recommend you to run them on severs with multiple threads.

